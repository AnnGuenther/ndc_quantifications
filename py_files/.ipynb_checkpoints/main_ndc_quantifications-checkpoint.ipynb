{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Author: Annika G端nther, annika.guenther@pik-potsdam.de  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Calculation of NDC target emissions\n",
    "\n",
    "The calculations are performed separately for national emissions excluding \n",
    "LULUCF and the LULUCF emissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Target types\n",
    "\n",
    "- **ABS**: absolute target emissions. E.g., target is to reduce emissions in 2030 \n",
    "to 500 MtCO2eq.\n",
    "- **BYT**: base year target. E.g., 20\\% emissions reduction compared to 2010 \n",
    "emissions in 2030.\n",
    "- **RRB**: relative reduction compared to BAU. E.g., 20\\% emissions reduction \n",
    "compared to business-as-usual (BAU) emissions in 2030.\n",
    "- **ARB**: absolute reduction compared to BAU. E.g., 350 MtCO2eq reduction \n",
    "compared to BAU emissions in 2030.\n",
    "- **RIT\\_BYT**: relative emissions intensity reduction compared to base year. \n",
    "E.g., 20\\% emissions intensity reduction compared to 2010 emissions intensity \n",
    "in 2030.\n",
    "- **RIT\\_BAU**: relative emissions intensity reduction compared to BAU. \n",
    "This is basically a simple RRB target, but some NDCs state it.\n",
    "- **AIT**: absolute emissions intensity. E.g., 2.1 tCO2eq/cap in 2030.\n",
    "- **NGT**: non-GHG targets. Nothing is calculated, baseline emissions are assumed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Information on targets\n",
    "\n",
    "- Target type (ABS, BYT, RRB, ARB, RIT\\_BYT, RIT\\_BAU, AIT), and reduction \n",
    "(\\% for BYT, RRB and RIT; absolute value for ARB) or target emissions (ABS).\n",
    "- Covered gases and categories, or pc\\_cov (in reference year and target year).\n",
    "- Emissions in the reference year and target year (per sector + gas, or \n",
    "national total if pc\\_cov is given).\n",
    "- If it is emissions intensity target:\n",
    "  - Reference: POP or GDP.\n",
    "  - Reference data in reference year and target year.\n",
    "  - If it is AIT: give target emissions intensity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### How to calculate an NDC target\n",
    "\n",
    "Generally: target emissions = sum of covered part of reference year emissions, \n",
    "reduced by \\% or absolute reduction, and the 'BAU' not-covered part of target \n",
    "year emissions.\n",
    "\n",
    "The general equation for an **emissions intensity base year target** (but also \n",
    "non-intensity target, and business-as-usual or BAU target) is\n",
    "\n",
    "$$E_{Tar} = NDC_{\\%lev} \\cdot \\frac{BL_{COV_{RY}}}{I_{RY}} \\cdot I_{TY} + \n",
    "BL_{nCOV_{TY}}$$\n",
    "\n",
    "- $E_{Tar}$ are the target emissions\n",
    "- $TY$ and $RY$ are the target year and the reference year. In the case of a \n",
    "*base year target*, the reference year is a historical year, while in the case \n",
    "of a *BAU target* $RY = TY$.\n",
    "- $I$ is the emissions intensity reference (either GDP or population). For \n",
    "*non-intensity targets*, $\\frac{I_{TY}}{I_{RY}}$ can be omitted from the \n",
    "equation (or set to $I_{TY} = I_{RY} = 1$).\n",
    "- $NDC_{\\%lev} = \\frac{100\\% - NDC_{\\%red}}{100\\%}$, with $NDC_{\\%red} = \n",
    "Percentage\\_Reduction\\_given\\_in\\_the\\_NDC$ (e.g., 20\\% reduction compared to \n",
    "BAU)\n",
    "- $BL$ are the national baseline emissions, with $BL_{COV}$ being the part of \n",
    "national baseline emissions covered by the NDC target (depending on the \n",
    "sectors and gases covered by the NDC target), and $BL_{nCOV}$ being the \n",
    "not-covered part of emissions.\n",
    "- $BL_{COV} = BL \\cdot PC\\_COV$, with $PC\\_COV = \n",
    "\\frac{\\sum emissions\\_from\\_covered\\_sector\\&gas\\_combinations}{national\\_emissions}$\n",
    "- $NDC_{\\%lev}$ is only applied to the covered part of emissions. \n",
    "$BL_{nCOV}$ is not 'touched' by the NDC target reductions and \n",
    "$BL_{nCOV_{TY}}$ is therefore added as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Target equations (per target type)\n",
    "\n",
    "$$E_{ABS} = NDC_{ABS}$$\n",
    "\n",
    "$$E_{BYT} = NDC_{\\%lev} \\cdot BL_{COV_{RY}} + BL_{nCOV_{TY}}$$\n",
    "\n",
    "$$E_{RRB} = NDC_{\\%lev} \\cdot BL_{COV_{TY}} + BL_{nCOV_{TY}}$$\n",
    "\n",
    "$$E_{ARB} = BL_{TY} - NDC_{abs\\_red}$$\n",
    "\n",
    "$$E_{RIT\\_BYT} = NDC_{\\%lev} \\cdot \\frac{BL_{COV_{RY}}}{I_{RY}} \\cdot I_{TY} \n",
    "+ BL_{nCOV_{TY}}$$\n",
    "\n",
    "$$E_{RIT\\_BAU} = E_{RRB} = NDC_{\\%lev} \\cdot BL_{COV_{TY}} + BL_{nCOV_{TY}}$$\n",
    "\n",
    "$$E_{AIT} = NDC_{AIT} \\cdot I_{TY}$$\n",
    "\n",
    "$$E_{NGT} = BL_{TY}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Percentage of emissions covered by NDC\n",
    "\n",
    "See preprocess\\_pc\\_cov\\_his.ipynb and preprocess\\_pc\\_cov\\_fut.ipynb.\n",
    "\n",
    "#### preprocess_pc_cov_his.ipynb\n",
    "\n",
    "- Based on PRIMAPHIST HISTCR emissions time series.\n",
    "- Per country (also includes the ISO3s that do not have independent data. Those countries do not have PRIMAPHIST data, so they are empty rows).\n",
    "- Categories and gases assessed:\n",
    "  - Main categories (IPC1, IPC2, IPCMAG, IPC4 and IPC5; namely Energy, IPPU, Agriculture, Waste and Other; excludes LULUCF - no emissions available since PRIMAPHIST20).\n",
    "  - Kyoto GHGs: CO$_2$, CH$_4$, N$_2$O, HFCS, PFCS, SF$_6$, NF$_3$.\n",
    "- For each of these categories / gases, the information on whether they are covered by the country's NDC is provided (csv-input, assessed by A. G端nther).\n",
    "- For all category + gas combinations, the emissions are counted as covered, if neither the category nor the gas are assumed not to be covered (neither category nor gas can contain a \"NO\").\n",
    "- If no information was available for all gases: only CO$_2$ assumed to be covered (in the csv-file already).\n",
    "- If no information was available for all sectors: only energy assumed to be covered. Case never happened.\n",
    "- If IPPU is not covered, the F-Gases are set to not-covered (in this script).\n",
    "- Category \"Other\" (IPC5) was set to \"YES\", if IPC1, 2, MAG, and 4 are assumed to be covered (int eh csv-file already).\n",
    "- Output: csv-file with all emissions time series per main_category + gas combination, together with the information if it is covered, and the country total covered / not-covered emissions, and the total values (per combination and total) for EARTH and EU28.\n",
    "\n",
    "#### preprocess_pc_cov_fut.ipynb\n",
    "\n",
    "- SSP data provided by J. G端tschow, are based on PRIMAPHIST20, with historic values being equal to PRIMAPHIST20.\n",
    "- For countries that cover all sectors (excl. LULUCF), but not all gases: the SSP emissions per gas are used to calculate pc\\_cov\\_fut.\n",
    "  - SSP data are available for KYOTOGHG, CO$_2$, CH$_4$, N$_2$O and FGASES:\n",
    "    - For countries that cover only some FGASES, the \\% share between HFCS, PFCS, SF$_6$ and NF$_3$ is kept constant (at last available values).\n",
    "    - The share per gas is applied to the future KYOTOGHG\\_IPCM0EL emissions data.\n",
    "- For countries that do not cover all sectors:\n",
    "  - Calculate the slope of pc\\_cov\\_his (2010 to most recent year with available data (\"mry\")).\n",
    "    - If abs(slope) < lim_slope: use the mean over 2010 to mry.\n",
    "    - If abs(slope) > lim_slope: calculate pc\\_cov\\_fut from the correlation between emi\\_tot\\_his and emi\\_cov\\_his. For 2010 to mry.\n",
    "        - If any(pc\\_cov\\_fut) > 90\\%, but not all(pc\\_cov\\_fut) > 90\\% --> set the pc\\_cov\\_fut > 90\\% to 90\\%.\n",
    "        - If any(pc\\_cov\\_fut) < 10\\%, but not all(pc\\_cov\\_fut) < 10\\% --> set the pc\\_cov\\_fut < 10\\% to 10\\%.\n",
    "        - Set min(pc\\_cov\\_fut) to 0\\% and max(pc\\_cov\\_fut) to 100\\%.\n",
    "  - If no future emissions data are available: use the mean over 2010 to mry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Approach for LULUCF\n",
    "\n",
    "If 'calc\\_lu' is set to 'True':\n",
    "- Target emissions are calculated separately for LULUCF (CO$_2$ + CH$_4$ + N$_2$O together).\n",
    "- Emissions time series\n",
    "  - Give time series for LULUCF emissions (taken from different sources, from which data are available).\n",
    "    - Source priorisation currently: 'CRF2019', 'BUR3IPCC2006I', 'BUR2IPCC2006I', 'BUR1IPCC2006I', 'UNFCCC2019BI', 'PRIMAPHIST20', 'FAO2019BI', 'EDGAR42COMPI'.\n",
    "    - So if CRF2019 data for a country are avaible, these are used, else BUR3, and so on.\n",
    "    - See agu\\_ndc\\_quantifications.m.\n",
    "    - Time series are filled with constant values (last available value kept constant until next available value; for 1990: first available value used). \n",
    "See agu\\_ndc\\_get\\_lulucf\\_data.m.\n",
    "- pc\\_cov\n",
    "  - Time series of pc\\_cov and pc\\_ncov (as parts of the LULUCF emissions data can also be negative, when being a sink) calculated based on CO2/CH4/N2O\\_IPCMLULUCF emissions data.\n",
    "  - See preprocess\\_pc\\_cov\\_lulucf.ipynb.\n",
    "- Per country: give a \\% value (sink\\_incr or srce\\_decr), determining how much of the given NDC \\%-reduction is applied to the covered part of LULUCF emissions.\n",
    "  - Values for sink\\_incr and srce\\_decr provided in preprocess\\_get\\_input\\_csv\\_files.ipynb.\n",
    "  - For base year targets: refyr equals base year, for BAU targets: refyr equals target year.\n",
    "  - If emi\\_lu\\_cov is negative in refyr: increase the sink-strength by sink\\_incr * NDC-\\%-red.\n",
    "  - If emi\\_lu\\_cov is positive in refyr: decrease the source by srce\\_decr * NDC-\\%-red.\n",
    "\n",
    "#### preprocess_pc_cov_lulucf.ipynb\n",
    "\n",
    "- Based on PRIMAPHIST HISTCR emissions time series.\n",
    "- Per country (also includes the ISO3s that do not have independent data. Those countries do not have PRIMAPHIST data, so they are empty rows).\n",
    "- Categories and gases assessed:\n",
    "  - IPCMLULUCF\n",
    "  - CO$_2$, CH$_4$, N$_2$O\n",
    "- For each of the categories / gases, the information on whether they are covered by the country's NDC is provided (csv-input, assessed by A. G端nther).\n",
    "- For all category + gas combinations, the emissions are counted as covered, if neither the category nor the gas are assumed not to be covered (neither category nor gas can contain a \"NO\").\n",
    "- If no information was available for all gases: only CO$_2$ assumed to be covered (in the csv-file already).\n",
    "- If no information was available for all sectors: only energy assumed to be covered. Case never happened.\n",
    "- If IPPU is not covered, the F-Gases are set to not-covered (in this script).\n",
    "- Output: csv-file with all emissions time series per IPCMLULUCF + gas combination, together with the information if it is covered, and the country total covered / not-covered emissions, and the total values (per combination and total) for EARTH and EU28."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Input needed\n",
    "\n",
    "Provide input in main\\_ndc\\_quantifications\\_input.ipynb.\n",
    "\n",
    "- Units for time series: emissions in MtCO2eq, population in Pers, GDP in 2011GKD.\n",
    "- Units for NDC input data (infos\\_from\\_ndcs\\_default.xlsx):\n",
    "  - MtCO2eq: BAU, baseyear emissions, ABS, ARB.\n",
    "  - tCO2eq/cap: AIT (all AIT targets are in emissions per capita)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import importlib\n",
    "from get_isos_for_groups.get_isos_for_groups import get_isos_for_groups as get_isos_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g., main_ndc_quantifications_input = 'main_ndc_quantifications_input'\n",
    "def main_ndc_quantifications(main_ndc_quantifications_input):\n",
    "    # %%\n",
    "    input_file = main_ndc_quantifications_input\n",
    "    main_ndc_quantifications_input = importlib.import_module(main_ndc_quantifications_input)\n",
    "    from main_ndc_quantifications_input import ndc_sheet, ndc_path, ndc_strengthen, ndc_type_prios\n",
    "    from main_ndc_quantifications_input import path_output, time_series_path, time_series_lu_path\n",
    "    from main_ndc_quantifications_input import scenario, gwp, calc_lu\n",
    "    from main_ndc_quantifications_input import pc_cov_predef\n",
    "    \n",
    "    # %%\n",
    "    # Write the input-info to a log-file in the output-folder.\n",
    "    fid = open(Path(path_output, 'log_file.md'), 'w')\n",
    "    fid.write(\"## Input from \" + input_file + \"\\n\")\n",
    "    fid.write(\"- **scenario:** \" + scenario  + \"\\n\")\n",
    "    fid.write(\"- **gwp:** \" + gwp + \"\\n\")\n",
    "    fid.write(\"- **time_series_path:**\\n\")\n",
    "    [fid.write(\"  - **\" + xx + \":** \" + str(time_series_path[xx]) + \"\\n\") \\\n",
    "               for xx in time_series_path]\n",
    "    fid.write(\"- **calc_lu:** \" + str(calc_lu) + \"\\n\")\n",
    "    fid.write(\"- **time_series_lu_path:**\\n\")\n",
    "    [fid.write(\"  - **\" + xx + \":** \" + str(time_series_lu_path[xx]) + \"\\n\") \\\n",
    "               for xx in time_series_lu_path]\n",
    "    fid.write(\"- **ndc_info:** \" + str(ndc_path) + \", **sheet** \" + ndc_sheet + \"\\n\")\n",
    "    fid.write(\"- **ndc_type_prios:**\\n\")\n",
    "    [fid.write(\"  - **\" + xx + \":** \" + str(ndc_type_prios[xx]) + \"\\n\") \\\n",
    "               for xx in ndc_type_prios]\n",
    "    fid.write(\"- **pc_cov_predef:**\\n\")\n",
    "    [fid.write(\"  - **\" + xx + \":** \" + str(pc_cov_predef[xx]) + \"\\n\") \\\n",
    "               for xx in pc_cov_predef]\n",
    "    fid.write(\"- **ndc_strengthen:**\\n\")\n",
    "    [fid.write(\"  - **\" + xx + \":** \" + str(ndc_strengthen[xx]) + \"\\n\") \\\n",
    "               for xx in ndc_strengthen]\n",
    "    fid.close()\n",
    "    \n",
    "    # %%\n",
    "    #import pandas as pd\n",
    "    #import copy\n",
    "    #import numpy as np\n",
    "    \n",
    "    def func_int_read_in_time_series(time_series, time_series_path, yrs_all_str, isos):\n",
    "        #####\n",
    "        # Read in time series (1990 - 2050) of emi, pc_cov, pop, gdp.\n",
    "        for val in time_series_path.keys():\n",
    "            ts_act = pd.read_csv(time_series_path[val])\n",
    "            for iso_act in ts_act.iso3:\n",
    "                ####\n",
    "                # Fill end of time series, if future values are missing (fill by mean over 2010 to most recent year).\n",
    "                ts_to_fill = copy.deepcopy(ts_act.loc[ts_act.iso3 == iso_act, yrs_all_str])\n",
    "                if (ts_to_fill.isnull().any().any() and not ts_to_fill.isnull().any().all()): # In our setup that should only happen at the end of historic time series.\n",
    "                    # Fill with constant value at the end (mean over 2010 to most recent value).\n",
    "                    ts_available = ts_to_fill.loc[:, [xx for xx in ts_to_fill.columns if ts_to_fill.loc[:, xx].notnull().all()]]\n",
    "                    yrs_not_available = [xx for xx in ts_to_fill.columns if ts_to_fill.loc[:, xx].isnull().all()]\n",
    "                    yrs_for_mean = ['Y' + str(xx) for xx in range(2010, int(ts_available.columns[-1][1:]) + 1)]\n",
    "                    ts_fill = ts_available.loc[:, yrs_for_mean].mean(axis=1).values\n",
    "                    ts_to_fill.loc[:, yrs_not_available] = ts_fill[0]\n",
    "                    ts_act.loc[ts_act.iso3 == iso_act, yrs_all_str] = ts_to_fill\n",
    "                    if type(ts_act.loc[ts_act.iso3 == iso_act, 'add_info']) == str:\n",
    "                        ts_act.loc[ts_act.iso3 == iso_act, 'add_info'] = ts_act.loc[ts_act.iso3 == iso_act, 'add_info'].values[0] + val + \\\n",
    "                            \": The time series was filled by the mean over 2010-\" + yrs_for_mean[-1][1:] + \", due to missing future values.\" + '\\n'\n",
    "                    else:\n",
    "                        ts_act.loc[ts_act.iso3 == iso_act, 'add_info'] = val + \\\n",
    "                            \": The time series was filled by the mean over 2010-\" + yrs_for_mean[-1][1:] + \", due to missing future values.\" + '\\n'\n",
    "                    # endif\n",
    "                # endif\n",
    "            # endfor\n",
    "            \n",
    "            #####\n",
    "            # Calculate the EU28 values.\n",
    "            if val != 'pc_cov_excl_lu': #Summing the percentages results in 28*100.\n",
    "                if ('EU28' not in list(ts_act.iso3)) or (ts_act.loc[ts_act.iso3 == 'EU28', yrs_all_str].isnull().all(axis=1).values[0]):\n",
    "                    if np.sum([1 for xx in isos['EU28'] if xx not in list(ts_act.iso3)]) > 0:\n",
    "                        print(\"Warning in main_ndc_quantifications: not all EU28 countries are added to the EU28 time series for \" + val + \"!\")\n",
    "                    # endif\n",
    "                    ts_add = pd.Series(index=ts_act.columns)\n",
    "                    ts_add[ts_add.index] = ts_act.loc[ts_act.iso3 == isos['EU28'][0], :].values[0]\n",
    "                    ts_add['iso3'] = 'EU28'\n",
    "                    ts_add[yrs_all_str] = ts_act.loc[ts_act.iso3.isin(isos['EU28']), yrs_all_str].sum(axis=0).values\n",
    "                    if 'EU28' in list(ts_act.iso3):\n",
    "                        ts_act.loc[ts_act.iso3 == 'EU28', :] = ts_add.values\n",
    "                    else:\n",
    "                        ts_act = ts_act.append(ts_add, ignore_index=True)\n",
    "                    # endif\n",
    "                # endif\n",
    "            # endif\n",
    "            \n",
    "            #####\n",
    "            # Put in iso3s as index, and reindex to EARTH isos plus 'EU28'.\n",
    "            ts_act.index = ts_act.iso3\n",
    "            ts_act = ts_act.reindex(index=sorted(isos['EARTH'] + ['EU28']))\n",
    "            #####\n",
    "            # Put ts_act into dictionary 'time_series'.\n",
    "            time_series[val] = ts_act\n",
    "        # endfor\n",
    "        \n",
    "        #####\n",
    "        return time_series\n",
    "    # enddef\n",
    "    \n",
    "    # %%\n",
    "    #import pandas as pd\n",
    "    \n",
    "    def func_int_read_in_time_series_lu(time_series, time_series_lu_path, isos):\n",
    "        #####\n",
    "        # Read in time series 1990-2050 (EU28 should be included already, done in preprocess_pc_cov_lulucf.ipynb).\n",
    "        # The filling of LULUCF time series was done in MATLAB already (agu_ndc_get_lulucf_data.m).\n",
    "        for val in time_series_lu_path.keys():\n",
    "            ts_act = pd.read_csv(time_series_lu_path[val])\n",
    "            #####\n",
    "            # Put in iso3s as index, and reindex to EARTH isos plus 'EU28'.\n",
    "            ts_act.index = ts_act.iso3\n",
    "            ts_act = ts_act.reindex(index=sorted(isos['EARTH'] + ['EU28']))\n",
    "            #####\n",
    "            # Put ts_act into dictionary 'time_series'.\n",
    "            time_series[val] = ts_act\n",
    "        # endfor\n",
    "        \n",
    "        #####\n",
    "        return time_series\n",
    "    # enddef\n",
    "    \n",
    "    # %%\n",
    "    #import pandas as pd\n",
    "    #import numpy as np\n",
    "    #from pathlib import Path\n",
    "    \n",
    "    def func_int_calc_targets(time_series, units, ndc, isos, gwp, scenario, yrs_all_str, path_output, calc_lu, \n",
    "                              pc_cov_predef, ndc_strengthen):\n",
    "        #####\n",
    "        # Set up for pd.DataFrame to store the in / output (for each target one row is added).\n",
    "        # Columns for LULUCF are added, even if it is excluded from entire calculations.\n",
    "        # cols['names'] will be columns, and cols['units'] will be set to first row.\n",
    "        cols = {'names': {'add_info': ['add_info'],\n",
    "                          'ndc': ['iso3', 'tar_type_used', 'tar_type_calc', 'tar_type_orig', 'condi', 'rge', 'ndc_val', 'ndc_strengthen', 'int_ref', 'refyr', 'taryr'],\n",
    "                          'tar': ['tar_emi_excl_lu', 'tar_emi_excl_lu_rel_red_cmp_bl', 'tar_emi_lu_only', 'tar_emi_tot'],\n",
    "                          'emi': ['gwp', 'scenario', 'emi_bl_excl_lu_refyr', 'emi_bl_excl_lu_taryr', 'emi_bl_lu_refyr', 'emi_bl_lu_taryr'],\n",
    "                          'pc_cov': ['pc_cov_predef', 'pc_cov_excl_lu_refyr', 'pc_cov_excl_lu_taryr', 'pc_cov_lu_refyr', 'pc_ncov_lu_refyr', 'pc_cov_lu_taryr', 'pc_ncov_lu_taryr'],\n",
    "                          'int_ref': ['pop_refyr', 'pop_taryr', 'gdp_refyr', 'gdp_taryr'],\n",
    "                          'cov_gases': ['CO2', 'CH4', 'N2O', 'HFCS', 'PFCS', 'SF6', 'NF3'],\n",
    "                          'cov_sectors': ['energy', 'ippu', 'agriculture', 'waste', 'other', 'lulucf'],\n",
    "                          'lulucf': ['sink_increase', 'source_decrease']},\n",
    "                'units': {'add_info': [None],\n",
    "                          'ndc': [None]*11,\n",
    "                          'tar': [units['emi'], '%', units['emi']],\n",
    "                          'emi': [None, None] + [units['emi']]*5,\n",
    "                          'pc_cov': ['%']*7,\n",
    "                          'int_ref': [units['pop'], units['pop'], units['gdp'], units['gdp']],\n",
    "                          'cov_gases': ['nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
    "                          'cov_sectors': ['nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
    "                          'lulucf': ['%']*2}}\n",
    "        \n",
    "        #####\n",
    "        # Dataframe with columns = all the items and sub-items in cols['names']:\n",
    "        data_out = pd.DataFrame(columns=[item for sublist in [cols['names'][xx] for xx in cols['names'].keys()] for item in sublist])\n",
    "        # Add the units as first row:\n",
    "        data_out = data_out.append(pd.Series([item for sublist in [cols['units'][xx] for xx in cols['units'].keys()] for item in sublist], \n",
    "                                             index=data_out.columns), ignore_index=True)\n",
    "            \n",
    "        #####\n",
    "        # Iterate through the iso3s in ndc (also the EU28 single countries, using the EU28 target info for the countries).\n",
    "        for iso_act in sorted(ndc.columns):        \n",
    "            add_info = ''\n",
    "            \n",
    "            #####\n",
    "            # For EU28 countries: use the ndc info from EU28.\n",
    "            if iso_act in isos['EU28']:\n",
    "                iso_ndc = 'EU28'\n",
    "            else:\n",
    "                iso_ndc = iso_act\n",
    "            # endif\n",
    "            \n",
    "            ######\n",
    "            # Get ndc information.\n",
    "            ndc_act = ndc.loc[:, iso_ndc]\n",
    "            ndc_act.index = [xx.upper() for xx in ndc_act.index]\n",
    "            \n",
    "            #####\n",
    "            # Get time series for emi_bl_excl_lu, emi_bl_lu, pc_cov, pop, gdp.\n",
    "            to_add = {'emi_bl_excl_lu': 'IPCM0EL', 'emi_bl_lu': 'IPCMLULUCF',\n",
    "                      'pc_cov_excl_lu': 'pc_cov_excl_lu',  'pc_cov_lu': 'pc_cov_lu', 'pc_ncov_lu': 'pc_ncov_lu',\n",
    "                      'pop': 'pop', 'gdp': 'gdp'}\n",
    "            ts_act = pd.DataFrame(index=to_add.keys(), columns=yrs_all_str)\n",
    "            for add in to_add.keys():\n",
    "                ts_to_add = time_series[to_add[add]]\n",
    "                if iso_act in list(ts_to_add.iso3):\n",
    "                    ts_act.loc[add, :] = ts_to_add.loc[ts_to_add.iso3 == iso_act, ts_act.columns].values\n",
    "                    add_info_act = ts_to_add.loc[ts_to_add.iso3 == iso_act, 'add_info'].values[0]\n",
    "                    if type(add_info_act) == str:\n",
    "                        add_info = add_info + add + \": \" + add_info_act + '\\n'\n",
    "                    # endif\n",
    "                    \n",
    "                    #####\n",
    "                    # Add the 'source' info for LULUCF.\n",
    "                    if add == 'emi_bl_lu':\n",
    "                        add_info2 = ts_to_add.loc[ts_to_add.iso3 == iso_act, 'source'].values[0]\n",
    "                        if type(add_info2) == str:\n",
    "                            add_info = add_info + add + \": source \" + add_info2 + '.\\n'\n",
    "                        # endif\n",
    "                    # endif\n",
    "                # endif\n",
    "            # endfor\n",
    "            \n",
    "            #####\n",
    "            # Get sink_incr and srce_decr.\n",
    "            if calc_lu:\n",
    "                if iso_act in list(time_series['sink_increase'].iso3):\n",
    "                    sink_incr = time_series['sink_increase'].loc[time_series['sink_increase'].iso3 == iso_act, 'sink_increase'].values[0]\n",
    "                    srce_decr = time_series['source_decrease'].loc[time_series['source_decrease'].iso3 == iso_act, 'source_decrease'].values[0]\n",
    "                else:\n",
    "                    sink_incr = np.nan\n",
    "                    srce_decr = np.nan\n",
    "                # endif\n",
    "            # endif\n",
    "            \n",
    "            #####\n",
    "            # Get info that is the same no matter which target year & un/conditional target it is, and put it into 'info'.\n",
    "            #####\n",
    "            # For 'info'\n",
    "            cols_11 = ['iso3', 'tar_type_calc', 'tar_type_orig', 'int_ref', 'refyr']\n",
    "            cols_12 = ['emi_bl_excl_lu_refyr', 'emi_bl_lu_refyr', 'pc_cov_excl_lu_refyr', 'pc_cov_lu_refyr', 'pc_ncov_lu_refyr']\n",
    "            # As LULUCF can also be negative: pc_cov and pc_ncov needed.\n",
    "            cols_13 = ['pop_refyr', 'gdp_refyr']\n",
    "            cols_14 = cols['names']['cov_gases']\n",
    "            cols_15 = cols['names']['cov_sectors']\n",
    "            #####\n",
    "            info = pd.Series(index = cols_11 + cols_12 + cols_13 + cols_14 + cols_15 + ['pc_cov_predef'])\n",
    "            info[cols_11] = [iso_act] + list(ndc_act.loc[['TYPE_CALC', 'TYPE_ORIG', 'INTENSITY_PERCAP_GDP', 'BASEYEAR']].values)\n",
    "            #####\n",
    "            # If  pc_cov_predef is given, with a value between 0 and 100, use it as pc_cov for all calculations.\n",
    "            if (pc_cov_predef['use_pc_cov_predef']) and (iso_act in pc_cov_predef['countries']):\n",
    "                info['pc_cov_predef'] = pc_cov_predef['pc_cov_predef']\n",
    "            # endif\n",
    "            #####\n",
    "            # Reference year (base year).\n",
    "            refyr_str = 'Y' + info['refyr']\n",
    "            if refyr_str != 'Ynan':\n",
    "                info[cols_12] = list(ts_act.loc[['emi_bl_excl_lu', 'emi_bl_lu', 'pc_cov_excl_lu', 'pc_cov_lu', 'pc_ncov_lu'], refyr_str].values)\n",
    "                info[cols_13] = list(ts_act.loc[['pop', 'gdp'], refyr_str].values)\n",
    "            # endif\n",
    "            info[cols_14] = ndc_act[[xx.upper() for xx in cols_14]]\n",
    "            info[cols_15] = ndc_act[[xx.upper() for xx in cols_15]]\n",
    "            \n",
    "            ######\n",
    "            # Calculate targets for all target types with values available in the input ndc-table.\n",
    "            for tar_type in ['ABS', 'BYT', 'RRB', 'ARB', 'RIT', 'AIT']:            \n",
    "                # Get all available target years & un/conditional & best/worst targets.\n",
    "                # ndc_val depends on the target type, either it is absolute emissions (ABS, ARB), a % (BYT, RRB, RIT), or an emissions intensity (AIT).\n",
    "                # ABS: target emissions in MtCO2eq.\n",
    "                # ARB: absolute  reduction in MtCO2eq (e.g., -3500 stands for 3500 MtCO2eq reduction).\n",
    "                # BYT, RRB, RIT: percentage reduction (e.g., -20 stands for 20% reduction).\n",
    "                # AIT: emissions intensity in target year, e.g., 3.2 stands for 3.2 t/cap or 3.2 t/GDP, when int_ref is POP or GDP, respectively.\n",
    "                ndc_vals_all = ndc_act.loc[[xx for xx in ndc_act.index if xx[:3] == tar_type]]\n",
    "                ndc_vals_all = ndc_vals_all.drop(index=[xx for xx in ndc_vals_all.index if ndc_vals_all[xx].upper() == 'NAN'])\n",
    "                \n",
    "                #####\n",
    "                # Iterate through the target years + un/conditional + best/worst.\n",
    "                for tars in ndc_vals_all.index:\n",
    "                    # Set up 'info_act' for the information in this iteration.\n",
    "                    #####\n",
    "                    # For 'info_act'\n",
    "                    cols_21 = ['condi', 'rge', 'ndc_val', 'taryr']\n",
    "                    cols_22 = ['tar_emi_excl_lu', 'tar_emi_excl_lu_rel_red_cmp_bl', 'tar_emi_lu_only', 'tar_emi_tot']\n",
    "                    cols_23 = ['gwp', 'scenario', 'emi_bl_excl_lu_taryr', 'emi_bl_lu_taryr', 'pc_cov_excl_lu_taryr', 'pc_cov_lu_taryr', 'pc_ncov_lu_taryr']\n",
    "                    cols_24 = ['pop_taryr', 'gdp_taryr']\n",
    "                    info_act = pd.Series(index = cols_21 + cols_22 + cols_23 + cols_24 + ['tar_type_used', 'ndc_strengthen', 'sink_increase', 'source_decrease'])\n",
    "                    \n",
    "                    #####\n",
    "                    # Is it un/conditional? Best/worst?\n",
    "                    if 'UNCONDITIONAL' in tars:\n",
    "                        info_act['condi'] = 'unconditional'\n",
    "                    else:\n",
    "                        info_act['condi'] = 'conditional'\n",
    "                    # endif\n",
    "                    if 'BEST' in tars:\n",
    "                        info_act['rge'] = 'best'\n",
    "                    else:\n",
    "                        info_act['rge'] = 'worst'\n",
    "                    # endif\n",
    "                    \n",
    "                    #####\n",
    "                    info_act['tar_type_used'] = tar_type\n",
    "                    # Get more information from ndc.\n",
    "                    info_act['ndc_val', 'taryr'] = [ndc_vals_all[tars], tars[-4:]]\n",
    "                    # Target year.\n",
    "                    taryr_str = 'Y' + info_act['taryr']\n",
    "                    info_act[cols_23] = [gwp, scenario] + list(ts_act.loc[['emi_bl_excl_lu', 'emi_bl_lu', 'pc_cov_excl_lu', 'pc_cov_lu', 'pc_ncov_lu'], taryr_str].values)\n",
    "                    info_act[cols_24] = list(ts_act.loc[['pop', 'gdp'], taryr_str].values)\n",
    "                    \n",
    "                    #####\n",
    "                    # Check if ndc_val seems ok.\n",
    "                    ndc_val = info_act['ndc_val']\n",
    "                    if info_act['tar_type_used'] == 'ABS':\n",
    "                        if 'MTCO2' not in ndc_val.upper():\n",
    "                            print(\"Warning in main_ndc_quantifications for \" + iso_act + \": tar_type_used is \" +\n",
    "                                  info_act['tar_type_used'] + \", but 'MtCO2' is not in ndc_val!\" +\n",
    "                                  \"\\n    ndc_val = \" + ndc_val)\n",
    "                        # endif\n",
    "                    # endif\n",
    "                    if info_act['tar_type_used'] in ['BYT', 'RRB', 'RIT']:\n",
    "                        if ('%' not in ndc_val) or ('-' not in ndc_val):\n",
    "                            print(\"Warning in main_ndc_quantifications for \" + iso_act + \": tar_type_used is \" +\n",
    "                                  info_act['tar_type_used'] + \", but '%' or/and '-' is not in ndc_val!\" +\n",
    "                                  \"\\n    ndc_val = \" + ndc_val)\n",
    "                        # endif\n",
    "                    # endif\n",
    "                    if info_act['tar_type_used'] == 'ARB':\n",
    "                        if ('MTCO2' not in ndc_val.upper()) or ('-' not in ndc_val):\n",
    "                            print(\"Warning in main_ndc_quantifications for \" + iso_act + \": tar_type_used is \" +\n",
    "                                  info_act['tar_type_used'] + \", but 'MtCO2' or/and '-' is not in ndc_val!\" +\n",
    "                                  \"\\n    ndc_val = \" + ndc_val)\n",
    "                        # endif\n",
    "                    # endif\n",
    "                    if info_act['tar_type_used'] == 'AIT':\n",
    "                        if ('TCO2' not in ndc_val.upper()) or ('MTCO2' in ndc_val.upper()):\n",
    "                            print(\"Warning in main_ndc_quantifications for \" + iso_act + \": tar_type_used is \" +\n",
    "                                  info_act['tar_type_used'] + \", but 'tCO2' or/and 'MtCO2' is in ndc_val!\" +\n",
    "                                  \"\\n    ndc_val = \" + ndc_val)\n",
    "                        # endif\n",
    "                    # endif\n",
    "                    \n",
    "                    #####\n",
    "                    # Get the numerical value from ndc_val (only looking at the letters up to the first space).\n",
    "                    ndc_val = ndc_val.replace('CO2', '') # If not the '2' will be kept for the numerical value.\n",
    "                    if ' ' in ndc_val:\n",
    "                        ndc_val = info_act['ndc_val'][:[xx for xx in range(len(info_act['ndc_val'])) if info_act['ndc_val'][xx] == ' '][0]]\n",
    "                    # endif\n",
    "                    ndc_val = float(''.join([xx for xx in ndc_val if xx in '0123456789eE.+-']))\n",
    "                    \n",
    "                    #####\n",
    "                    # If strengthen NDC is chosen.\n",
    "                    if ndc_strengthen['use_ndc_strengthen']:\n",
    "                        if iso_act in ndc_strengthen['countries']:\n",
    "                            if info_act['tar_type_used'] in ['BYT', 'RRB', 'RIT']:\n",
    "                                if ndc_strengthen['how_to'] == 'multiply':\n",
    "                                    ndc_val_new = ndc_val * (1. + ndc_strengthen['pc']/100.)\n",
    "                                    info_act['ndc_strengthen'] = \"Multiply ndc_val with \" + str(1. + ndc_strengthen['pc']/100.) + \".\"\n",
    "                                # endif\n",
    "                                if ndc_strengthen['how_to'] == 'add':\n",
    "                                    ndc_val_new = ndc_val - ndc_strengthen['pc'] # ndc_val usually is negative, e.g., -20%.\n",
    "                                    info_act['ndc_strengthen'] = \"Add \" + str(ndc_strengthen['pc']) + \"% to ndc_val.\"\n",
    "                                # endif\n",
    "                                # If ndc_val_new is bigger than a 100% reduction, set it to 100% reduction.\n",
    "                                if (ndc_val_new < -100.) and (ndc_val > -100.):\n",
    "                                    ndc_val = -100.\n",
    "                                else:\n",
    "                                    ndc_val = ndc_val_new\n",
    "                                # endif\n",
    "                            # endif\n",
    "                        # endif\n",
    "                    # endif\n",
    "                    \n",
    "                    #####\n",
    "                    # Get the % reduction (only used in calculations of relative targets).\n",
    "                    red_excl_lu = 1. + ndc_val / 100.\n",
    "                    \n",
    "                    #####\n",
    "                    # If  pc_cov_predef is given (set to 100%), use it as pc_cov for all calculations.\n",
    "                    if (pc_cov_predef['use_pc_cov_predef']) and (iso_act in pc_cov_predef['countries']):\n",
    "                        pc_cov_excl_lu_refyr = pc_cov_predef['pc_cov_predef']\n",
    "                        pc_cov_excl_lu_taryr = pc_cov_predef['pc_cov_predef']\n",
    "                        pc_cov_lu_refyr = pc_cov_predef['pc_cov_predef']\n",
    "                        pc_cov_lu_taryr = pc_cov_predef['pc_cov_predef']\n",
    "                        pc_ncov_lu_taryr = 100. - pc_cov_predef['pc_cov_predef']\n",
    "                    else:\n",
    "                        pc_cov_excl_lu_refyr = info['pc_cov_excl_lu_refyr']\n",
    "                        pc_cov_excl_lu_taryr = info_act['pc_cov_excl_lu_taryr']\n",
    "                        pc_cov_lu_refyr = info['pc_cov_lu_refyr']\n",
    "                        pc_cov_lu_taryr = info_act['pc_cov_lu_taryr']\n",
    "                        pc_ncov_lu_taryr = info_act['pc_ncov_lu_taryr']\n",
    "                    # endif\n",
    "                    \n",
    "                    #####\n",
    "                    # If LULUCF is calculated, get the % 'reduction' applied to covered LULUCF emissions.\n",
    "                    # Depending on whether the covered part of LULUCF baseline emissions in the reference year is negative or positive.\n",
    "                    # Reference year depends on whether it is a target comparing to a base year or the BAU target year emissions.\n",
    "                    if calc_lu:\n",
    "                        info_act['sink_increase', 'source_decrease'] = [sink_incr, srce_decr]\n",
    "                        lu_cov_refyr = info['emi_bl_lu_refyr'] * pc_cov_lu_refyr\n",
    "                        lu_cov_taryr = info_act['emi_bl_lu_taryr'] * pc_cov_lu_taryr\n",
    "                        # For relative targets.\n",
    "                        red_lu_sink = 1. - ndc_val / 100. * sink_incr / 100.\n",
    "                        red_lu_srce = 1 + ndc_val / 100. * srce_decr / 100.\n",
    "                        if refyr_str != 'Ynan': # refyr == base year.\n",
    "                            if lu_cov_refyr < 0:\n",
    "                                red_lu = red_lu_sink\n",
    "                            elif lu_cov_refyr >= 0:\n",
    "                                red_lu = red_lu_srce\n",
    "                            # endif\n",
    "                        else: # refyr == taryr.\n",
    "                            if lu_cov_taryr < 0:\n",
    "                                red_lu = red_lu_sink\n",
    "                            elif lu_cov_taryr >= 0:\n",
    "                                red_lu = red_lu_srce\n",
    "                            # endif\n",
    "                        # endif\n",
    "                    # endif\n",
    "                    \n",
    "                    #####\n",
    "                    # Calculate the target year emissions depending on the target type.\n",
    "                    if info_act['tar_type_used'] == 'ABS':\n",
    "                        info_act['tar_emi_excl_lu'] = ndc_val\n",
    "                    # endif\n",
    "                    if info_act['tar_type_used'] == 'BYT':\n",
    "                        info_act['tar_emi_excl_lu'] = info['emi_bl_excl_lu_refyr'] * pc_cov_excl_lu_refyr/100. * red_excl_lu +\\\n",
    "                                                      info_act['emi_bl_excl_lu_taryr'] * (1. - pc_cov_excl_lu_taryr/100.)\n",
    "                        if calc_lu:\n",
    "                            info_act['tar_emi_lu_only'] = info['emi_bl_lu_refyr'] * pc_cov_lu_refyr/100. * red_lu + \\\n",
    "                                                     info_act['emi_bl_lu_taryr'] * pc_ncov_lu_taryr/100.\n",
    "                        # endif\n",
    "                    # endif\n",
    "                    if info_act['tar_type_used'] == 'RRB':\n",
    "                        info_act['tar_emi_excl_lu'] = info_act['emi_bl_excl_lu_taryr'] * pc_cov_excl_lu_taryr/100. * red_excl_lu +\\\n",
    "                                                      info_act['emi_bl_excl_lu_taryr'] * (1. - pc_cov_excl_lu_taryr/100.)\n",
    "                        if calc_lu:\n",
    "                            info_act['tar_emi_lu_only'] = info_act['emi_bl_lu_taryr'] * pc_cov_lu_taryr/100. * red_lu +\\\n",
    "                                                     info_act['emi_bl_lu_taryr'] * pc_ncov_lu_taryr/100.\n",
    "                        # endif\n",
    "                    # endif\n",
    "                    if info_act['tar_type_used'] == 'ARB': # We currently do not have the input for ARB for LU ...\n",
    "                        info_act['tar_emi_excl_lu'] = info_act['emi_bl_excl_lu_taryr'] + ndc_val\n",
    "                    # endif\n",
    "                    if info_act['tar_type_used'] == 'RIT':\n",
    "                        if refyr_str == taryr_str:\n",
    "                            # Like BAU:\n",
    "                            info_act['tar_emi_excl_lu'] = info_act['emi_bl_excl_lu_taryr'] * pc_cov_excl_lu_taryr/100. * red_excl_lu +\\\n",
    "                                                          info_act['emi_bl_excl_lu_taryr'] * (1. - pc_cov_excl_lu_taryr/100.)\n",
    "                            if calc_lu:\n",
    "                                info_act['tar_emi_lu_only'] = info_act['emi_bl_lu_taryr'] * pc_cov_lu_taryr/100. * red_lu +\\\n",
    "                                                         info_act['emi_bl_lu_taryr'] * (1. - pc_ncov_lu_taryr/100.)\n",
    "                            # endif\n",
    "                        else:\n",
    "                            # Compared to base year:\n",
    "                            info_act['tar_emi_excl_lu'] = info_act[info['int_ref'].lower() + '_taryr'] / info[info['int_ref'].lower() + '_refyr'] *\\\n",
    "                                                          info['emi_bl_excl_lu_refyr'] * pc_cov_excl_lu_refyr/100. * red_excl_lu +\\\n",
    "                                                          info_act['emi_bl_excl_lu_taryr'] * (1. - pc_cov_excl_lu_taryr/100.)\n",
    "                            if calc_lu:\n",
    "                                info_act['tar_emi_lu_only'] = info_act[info['int_ref'].lower() + '_taryr'] / info[info['int_ref'].lower() + '_refyr'] *\\\n",
    "                                                         info['emi_bl_excl_lu_refyr'] * pc_cov_excl_lu_refyr/100. * red_lu +\\\n",
    "                                                         info_act['emi_bl_excl_lu_taryr'] * (1. - pc_cov_excl_lu_taryr/100.)\n",
    "                            # endif\n",
    "                        # endif\n",
    "                    # endif\n",
    "                    if info_act['tar_type_used'] == 'AIT':\n",
    "                        if 'CAP' in info_act['ndc_val'].upper():\n",
    "                            info_act['tar_emi_excl_lu'] = ndc_val * 1e-6 * info_act['pop_taryr']\n",
    "                        elif 'GDP' in info_act['ndc_val'].upper():\n",
    "                            info_act['tar_emi_excl_lu'] = ndc_val * 1e-6 * info_act['gdp_taryr']\n",
    "                        else:\n",
    "                            print(\"Warning in main_ndc_quantifications.ipynb: for \" + iso_act + \" AIT, it is not clear which reference to use. \" +\n",
    "                                 \"The target is \" + info_act['ndc_val'] + \". Nothing has been calculated.\")\n",
    "                        # endif\n",
    "                    # endif\n",
    "                    \n",
    "                    #####\n",
    "                    # Total target:\n",
    "                    if calc_lu:\n",
    "                        info_act['tar_emi_tot'] = info_act['tar_emi_excl_lu'] + info_act['tar_emi_lu_only']\n",
    "                    # endif\n",
    "                    \n",
    "                    #####\n",
    "                    # % reduction against BAU.\n",
    "                    info_act['tar_emi_excl_lu_rel_red_cmp_bl'] = 100. * (info_act['tar_emi_excl_lu']/info_act['emi_bl_excl_lu_taryr'] - 1.)\n",
    "                    \n",
    "                    #####\n",
    "                    # Add calculations to 'data_act'.\n",
    "                    data_act = pd.Series(index=data_out.columns)\n",
    "                    data_act[info.index] = info\n",
    "                    data_act[info_act.index] = info_act\n",
    "                    data_act['add_info'] = add_info\n",
    "                    \n",
    "                    #####\n",
    "                    # Add 'data_act' to 'data_out'.\n",
    "                    data_out = data_out.append(data_act, ignore_index=True)\n",
    "                # endfor\n",
    "            # endif\n",
    "        # endfor\n",
    "        \n",
    "        #####\n",
    "        # Write out data.\n",
    "        data_out.to_csv(Path(path_output, 'ndc_targets.csv'), index=False)\n",
    "        print(\"done calculating the targets ...\")\n",
    "        \n",
    "        #####\n",
    "        return data_out\n",
    "    # enddef\n",
    "    \n",
    "    # %%\n",
    "    #import pandas as pd\n",
    "    #import numpy as np\n",
    "    #from pathlib import Path\n",
    "    \n",
    "    def func_int_calc_pathways_per_country(time_series, data_out, input_pathways, target_name, file_name, path_output, \n",
    "                                           yrs_all_str, yrs_pathway_str, isos, units, ndc_type_prios):\n",
    "        #####\n",
    "        # Calculate the pathway per country and target conditionality + range (un/conditional best/worst).\n",
    "        yrs_pathway_int = [int(xx[1:]) for xx in yrs_pathway_str]\n",
    "        \n",
    "        #####\n",
    "        # Set up 'pathways_all'.\n",
    "        pathways_all = pd.DataFrame(columns = ['add_info', 'iso3', 'tar_type_used', 'condi', 'rge', 'entity', 'category', 'unit', 'gwp'] + yrs_all_str)\n",
    "        \n",
    "        #####\n",
    "        # Get time series for emi_bl, pc_cov, pop, gdp.\n",
    "        ts_emi_bl = time_series[input_pathways['emi_bl']['name']]\n",
    "        ts_pc_cov = time_series[input_pathways['pc_cov']['name']]\n",
    "        ts_pop = time_series[input_pathways['pop']['name']]\n",
    "        ts_gdp = time_series[input_pathways['gdp']['name']]\n",
    "        \n",
    "        #####\n",
    "        # Iterate through EARTH countries (only with independent data), EU28 (also as single countries).\n",
    "        for iso_act in sorted(isos['EARTH'] + ['EU28']):\n",
    "            #####\n",
    "            # Set up 'add_data' for that country.\n",
    "            add_data = pd.DataFrame(index=['emi', 'pc_cov', 'pop', 'gdp'], columns=pathways_all.columns)\n",
    "            add_data.loc[:, 'iso3'] = iso_act\n",
    "            add_data.loc[:, ['entity', 'category']] = [[input_pathways[xx]['ent'], input_pathways[xx]['cat']] for xx in input_pathways.keys()]\n",
    "            \n",
    "            #####\n",
    "            # Put in data for emi_bl, pc_cov, pop and gdp, for the current country.\n",
    "            emi_bl_act = ts_emi_bl.loc[ts_emi_bl.iso3 == iso_act, :]\n",
    "            if 0 not in emi_bl_act.shape:\n",
    "                add_data.loc['emi', ['unit', 'gwp'] + yrs_all_str] = list(emi_bl_act.loc[:, ['unit', 'gwp']].values[0]) + list(emi_bl_act[yrs_all_str].values[0])\n",
    "                pc_cov_act = ts_pc_cov.loc[ts_pc_cov.iso3 == iso_act, :]\n",
    "                if 0 not in pc_cov_act.shape:\n",
    "                    add_data.loc['pc_cov', ['unit', 'gwp'] + yrs_all_str] = list(pc_cov_act.loc[:, ['unit', 'gwp']].values[0]) + list(pc_cov_act[yrs_all_str].values[0])\n",
    "                # endif\n",
    "                pop_act = ts_pop.loc[ts_pop.iso3 == iso_act, :]\n",
    "                if 0 not in pop_act.shape:\n",
    "                    add_data.loc['pop', ['unit'] + yrs_all_str] = [units['pop']] + list(pop_act[yrs_all_str].values[0])\n",
    "                # endif\n",
    "                # Put gdp to pathways_all:\n",
    "                gdp_act = ts_gdp.loc[ts_gdp.iso3 == iso_act, :]\n",
    "                if 0 not in gdp_act.shape:\n",
    "                    add_data.loc['gdp', ['unit'] + yrs_all_str] = [units['gdp']] + list(gdp_act[yrs_all_str].values[0])\n",
    "                # endif\n",
    "                # Add 'add_data' to 'pathways_all'.\n",
    "                pathways_all = pathways_all.append(add_data, ignore_index=True)\n",
    "                \n",
    "                #####\n",
    "                # Get target data (calculated above).\n",
    "                if iso_act in list(data_out.iso3):\n",
    "                    tars_act = data_out.loc[data_out.iso3 == iso_act, :]\n",
    "                    \n",
    "                    # Check if there are values for ndc_type_prio and use it for calculation if so.\n",
    "                    if iso_act in ndc_type_prios['countries']:\n",
    "                        tars_available = []\n",
    "                        for type_prio in ndc_type_prios:\n",
    "                            if type_prio == 'TYPE_CALC':\n",
    "                                tars_available = tars_available + [tars_act.loc[tars_act.index[0], 'tar_type_calc']]\n",
    "                            elif type_prio == 'TYPE_ORIG':\n",
    "                                tars_available = tars_available + [tars_act.loc[tars_act.index[0], 'tar_type_calc']]\n",
    "                            else:\n",
    "                                vals_available = [tars_act.loc[xx, 'tar_type_used'] for xx in tars_act.index\n",
    "                                                  if tars_act.loc[xx, 'tar_type_used'] == type_prio]\n",
    "                                if len(vals_available) > 0:\n",
    "                                    tars_available = tars_available + [type_prio]\n",
    "                                # endif\n",
    "                            # endif\n",
    "                        # endfor\n",
    "                        if len(tars_available) > 0:\n",
    "                            tar_used = tars_available[0] # Use the first available target type.\n",
    "                        else:\n",
    "                            tar_used = tars_act.loc[tars_act.index[0], 'tar_type_calc']\n",
    "                        # endif\n",
    "                    else:\n",
    "                        tar_used = tars_act.loc[tars_act.index[0], 'tar_type_calc']\n",
    "                    # endif\n",
    "                    tars_act = tars_act.loc[tars_act.tar_type_used == tar_used, :]\n",
    "                    \n",
    "                    #####\n",
    "                    # Set up 'targets_act' for the pathways per un/conditional & best/worst.\n",
    "                    targets_act = pd.DataFrame(index=['unconditional_worst', 'unconditional_best', 'conditional_worst', 'conditional_best'], \n",
    "                                               columns=pathways_all.columns)\n",
    "                    #####\n",
    "                    # Which target type is used for the pathway calculation.\n",
    "                    targets_act.loc[:, 'tar_type_used'] = tar_used\n",
    "                    \n",
    "                    #####\n",
    "                    # Per un/conditional_best/worst, put all the target emissions to the correct year in 'targets_act'.\n",
    "                    for tars in tars_act.index:\n",
    "                        condi_rge = tars_act.loc[tars, 'condi'] + '_' + tars_act.loc[tars, 'rge']\n",
    "                        targets_act.loc[condi_rge, 'Y' + str(tars_act.loc[tars, 'taryr'])] = tars_act.loc[tars, target_name]\n",
    "                        targets_act.loc[condi_rge, ['condi', 'rge']] = [tars_act.loc[tars, 'condi'], tars_act.loc[tars, 'rge']]\n",
    "                    # endfor\n",
    "                    \n",
    "                    #####\n",
    "                    # If there is a value in unconditional_best in a year, but not in unconditional_worst, put it there.\n",
    "                    yrs_info = []\n",
    "                    for yr_act in yrs_pathway_str:\n",
    "                        if (~np.isnan(targets_act.loc['unconditional_best', yr_act]) \\\n",
    "                        and np.isnan(targets_act.loc['unconditional_worst', yr_act])):\n",
    "                            targets_act.loc['unconditional_worst', yr_act] = targets_act.loc['unconditional_best', yr_act]\n",
    "                            yrs_info = yrs_info + [yr_act[1:]]\n",
    "                        # endif\n",
    "                    # endfor\n",
    "                    if len(yrs_info) > 0:\n",
    "                        targets_act.loc['unconditional_worst', 'add_info'] = \\\n",
    "                            \"The target value from 'unconditional_best' was used for 'unconditional_worst' in \" + ', '.join(yrs_info) + \".\\n\"\n",
    "                    # endif\n",
    "                    \n",
    "                    #####\n",
    "                    # If there is a value in conditional_best in a year, but not in conditional_worst, put it there.\n",
    "                    yrs_info = []\n",
    "                    for yr_act in yrs_pathway_str:\n",
    "                        if (~np.isnan(targets_act.loc['conditional_best', yr_act]) \\\n",
    "                        and np.isnan(targets_act.loc['conditional_worst', yr_act])):\n",
    "                            targets_act.loc['conditional_worst', yr_act] = targets_act.loc['conditional_best', yr_act]\n",
    "                            yrs_info = yrs_info + [yr_act[1:]]\n",
    "                        # endif\n",
    "                    # endfor\n",
    "                    if len(yrs_info) > 0:\n",
    "                        targets_act.loc['conditional_worst', 'add_info'] = \\\n",
    "                            \"The target value from 'conditional_best' was used for 'conditional_worst' in \" + ', '.join(yrs_info) + \".\\n\"\n",
    "                    # endif\n",
    "                    \n",
    "                    #####\n",
    "                    # If there is a value in unconditional in a year, but not in conditional, put it there (the one stored in 'unconditional_worse').\n",
    "                    yrs_info = []\n",
    "                    for yr_act in yrs_pathway_str:\n",
    "                        if (~np.isnan(targets_act.loc['unconditional_worst', yr_act]) \\\n",
    "                        and np.isnan(targets_act.loc['conditional_best', yr_act])):\n",
    "                            targets_act.loc[['conditional_worst', 'conditional_best'], yr_act] = targets_act.loc['unconditional_worst', yr_act]\n",
    "                            yrs_info = yrs_info + [yr_act[1:]]\n",
    "                        # endif\n",
    "                    # endfor\n",
    "                    if len(yrs_info) > 0:\n",
    "                        if type(targets_act.loc['conditional_worst', 'add_info']) == str:\n",
    "                            targets_act.loc['conditional_worst', 'add_info'] = targets_act.loc['conditional_worst', 'add_info'] + \\\n",
    "                                \"The target value from 'unconditional_worst' was used for 'conditional_worst' in \" + ', '.join(yrs_info) + \".\\n\"\n",
    "                        else:\n",
    "                            targets_act.loc['conditional_worst', 'add_info'] = \\\n",
    "                                \"The target value from 'unconditional_worst' was used for 'conditional_worst' in \" + ', '.join(yrs_info) + \".\\n\"\n",
    "                        # endif\n",
    "                        targets_act.loc['conditional_best', 'add_info'] = \\\n",
    "                            \"The target value from 'unconditional_worst' was used for 'unconditional_worst' in \" + ', '.join(yrs_info) + \".\\n\"\n",
    "                    # endif\n",
    "                    \n",
    "                    #####\n",
    "                    # Calculate the pathways per un/conditional_best/worst, assuming a linear in/decrease of the % difference to the baseline emissions.\n",
    "                    # E.g., if the country has one unconditional_best target that equals a reduction of 20% in 2030 (compared to baseline emissions):\n",
    "                    # the pathway has a 0% reduction in 2020, in 2025 it is a 10% reduction, and in 2030 the given 20% reduction.\n",
    "                    # Iterate through un/conditional_best/worst.\n",
    "                    for tars in targets_act.index:\n",
    "                        #####\n",
    "                        # Set up 'pathway_calc' to store the pathways for the current 'tars'.\n",
    "                        pathway_calc = pd.DataFrame(index=['years', 'targets', 'baseline', 'pc_diff', 'pathway'], columns=pathways_all.columns)\n",
    "                        #####\n",
    "                        pathway_calc.loc[:, 'add_info'] = targets_act.loc[tars, 'add_info']\n",
    "                        pathway_calc.loc[:, 'iso3'] = iso_act\n",
    "                        pathway_calc.loc[:, 'tar_type_used'] = tar_used\n",
    "                        pathway_calc.loc[:, ['entity', 'category', 'unit', 'gwp']] = emi_bl_act[['entity', 'category', 'unit', 'gwp']].values[0]\n",
    "                        #####\n",
    "                        # Un/conditiona best/worst?\n",
    "                        if 'unconditional' in tars:\n",
    "                            pathway_calc.loc[:, 'condi'] = 'unconditional'\n",
    "                        else:\n",
    "                            pathway_calc.loc[:, 'condi'] = 'conditional'\n",
    "                        # endif\n",
    "                        if 'best' in tars:\n",
    "                            pathway_calc.loc[:, 'rge'] = 'best'\n",
    "                        else:\n",
    "                            pathway_calc.loc[:, 'rge'] = 'worst'\n",
    "                        # endif\n",
    "                        #####\n",
    "                        pathway_calc.loc['years', yrs_pathway_str] = yrs_pathway_int\n",
    "                        # For each target year get the target year emissions.\n",
    "                        pathway_calc.loc['targets', :] = targets_act.loc[tars, :].values\n",
    "                        # Baseline emissions.\n",
    "                        pathway_calc.loc['baseline', :] = emi_bl_act.reindex(columns=pathway_calc.columns).values[0]\n",
    "                        #####\n",
    "                        # If there is no target for 2020, put in the baseline emissions:\n",
    "                        yr_act = yrs_pathway_str[0]\n",
    "                        if np.isnan(pathway_calc.loc['targets', yr_act]):\n",
    "                            pathway_calc.loc['targets', yr_act] = pathway_calc.loc['baseline', yr_act]\n",
    "                        # endif\n",
    "                        \n",
    "                        #####\n",
    "                        # Calculate the percentage level, meaning how much percent of the baseline emissions do the single target emissions present.\n",
    "                        # Replace zeros by nan, before division:\n",
    "                        div_act = pathway_calc.loc['baseline', yrs_pathway_str].values\n",
    "                        div_act = [div_act[xx] if div_act[xx] != 0 else np.nan for xx in range(len(div_act))]\n",
    "                        pathway_calc.loc['pc_level', yrs_pathway_str] = pathway_calc.loc['targets', yrs_pathway_str].div(div_act)\n",
    "                        \n",
    "                        #####\n",
    "                        # pc_level: interpolate between available values, and keep the last value constant.\n",
    "                        # E.g., 2020 is 100%, 2030 is 80%. For 2025 it is 100% + (80%-100%)/(2030-2020) * (2025-2020) = 90%.\n",
    "                        available_years = [xx for xx in yrs_pathway_str if ~np.isnan(pathway_calc.loc['pc_level', xx])]\n",
    "                        if len(available_years) > 0:\n",
    "                            available_vals = [pathway_calc.loc['pc_level', xx] for xx in available_years]\n",
    "                            available_years = [int(xx[1:]) for xx in available_years]\n",
    "                            for interp in range(len(available_vals) - 1):\n",
    "                                interp_vals = [available_vals[interp] + \\\n",
    "                                               (available_vals[interp + 1] - available_vals[interp]) / (available_years[interp + 1] - available_years[interp]) * \\\n",
    "                                               (xx - available_years[interp]) \\\n",
    "                                               for xx in range(available_years[interp], available_years[interp + 1])]\n",
    "                                pathway_calc.loc['pc_level', ['Y' + str(xx) for xx in np.arange(available_years[interp], available_years[interp + 1])]] = interp_vals\n",
    "                            # endfor\n",
    "                            # Constant value of pc_level after last available target.\n",
    "                            pathway_calc.loc['pc_level', ['Y' + str(xx) for xx in np.arange(available_years[-1], yrs_pathway_int[-1] + 1)]] = \\\n",
    "                                pathway_calc.loc['pc_level', 'Y' + str(available_years[-1])]\n",
    "                        # endif\n",
    "                        #####\n",
    "                        if len(available_years) <= 0:\n",
    "                            # All values of pc_level are 100% (= baseline emissions):\n",
    "                            pathway_calc.loc['pc_level', yrs_pathway_str] = 1.\n",
    "                        # endif\n",
    "                        #####\n",
    "                        # Years up to 2019 are baseline emissions.\n",
    "                        pathway_calc.loc['pathway', yrs_all_str] = pathway_calc.loc['baseline', yrs_all_str]\n",
    "                        #####\n",
    "                        # Apply pc_level to baseline emissions.\n",
    "                        pathway_calc.loc['pathway', yrs_pathway_str] = pathway_calc.loc['pc_level', yrs_pathway_str].multiply(pathway_calc.loc['baseline', yrs_pathway_str])\n",
    "                        \n",
    "                        #####\n",
    "                        # Put the calculated 'pathway' to 'pathways_all'.\n",
    "                        pathways_all = pathways_all.append(pathway_calc.loc['pathway', :], ignore_index=True)\n",
    "                    # endfor\n",
    "                # endif\n",
    "                \n",
    "                # If iso_act has no targets, use the baseline emissions for all un/conditional_best/worst pathways.\n",
    "                if not iso_act in list(data_out.iso3):\n",
    "                    targets_act = pd.DataFrame(index=['unconditional_worst', 'unconditional_best', 'conditional_worst', 'conditional_best'], columns=pathways_all.columns)\n",
    "                    targets_act.loc[:, ['condi', 'rge']] = [['unconditional', 'worst'], ['unconditional', 'best'], ['conditional', 'worst'], ['conditional', 'best']]\n",
    "                    targets_act.loc[:, 'add_info'] = \"No targets calculated, so the baseline emissions are put in as target pathways for all un/conditional best/worst pathways.\\n\"\n",
    "                    targets_act.loc[:, ['entity', 'category', 'unit', 'gwp'] + yrs_all_str] = list(emi_bl_act.loc[:, ['entity', 'category', 'unit', 'gwp']].values[0]) + list(emi_bl_act[yrs_all_str].values[0])\n",
    "                    targets_act.loc[:, 'iso3'] = iso_act\n",
    "                    targets_act.loc[:, 'tar_type_used'] = 'baseline_emissions'\n",
    "                    # Put the data to 'pathways_all'.\n",
    "                    pathways_all = pathways_all.append(targets_act, ignore_index=True)\n",
    "                # endif\n",
    "            # endif\n",
    "        # endfor\n",
    "        \n",
    "        # Write out 'pathways_all'.\n",
    "        pathways_all.to_csv(Path(path_output, file_name), index=False)\n",
    "        print(\"done calculating the per-country pathways ...\")\n",
    "        \n",
    "        #####\n",
    "        return pathways_all\n",
    "    # enddef\n",
    "    \n",
    "    # %%\n",
    "    #import pandas as pd\n",
    "    #from pathlib import Path\n",
    "    #from get_isos_for_groups.get_isos_for_groups import get_isos_for_groups as get_isos_groups\n",
    "    \n",
    "    def func_int_calc_pathway_per_group(pathways_all, input_pathways, yrs_all_str, isos, units, gwp, path_output, file_name):\n",
    "        # Calculate the emissions pathway for a group of countries by summing up all available per-country pathways, per un/conditional_best/worst.\n",
    "        #####\n",
    "        # Groups for which to get the pathways.\n",
    "        groups = sorted(['ANNEXI', 'ANNEXI_KAZ', 'AOSIS', 'AR5', 'AG', 'BRICS', 'EIG', 'EU28', 'G7', 'G20', 'G77',\n",
    "                  'GRADUATED_LDCS', 'IMO', 'LDC', 'LLDC', 'NON_ANNEXI', 'OECD', 'OPEC', 'SIDS',\n",
    "                  'UMBRELLA', 'UNFCCC', 'UN_REGIONAL_GROUPS', 'AILAC', 'ALBA', 'APG', 'BASIC', 'CACAM', 'CD', 'CfRN', 'CVF', 'EARTH',\n",
    "                  'EEG', 'EIT', 'G77+China', 'GRULAC', 'KYOTO', 'LAS', 'LMDC', 'PA', 'SICA', 'UN', 'WEOG'])\n",
    "        \n",
    "        #####\n",
    "        # Put up 'pathways_groups' to store all the pathways.\n",
    "        pathways_groups = pd.DataFrame(columns=['add_info', 'group', 'iso3s', 'iso3s_adapted', 'iso3s_missing', 'condi', 'rge', 'entity', 'category', 'unit', 'gwp'] + yrs_all_str)\n",
    "        \n",
    "        #####\n",
    "        # Get emi_bl, pc_cov, pop and gdp.\n",
    "        emi_bl_name = input_pathways['emi_bl']['name']\n",
    "        pc_cov_name = input_pathways['pc_cov']['name']\n",
    "        pop_name = input_pathways['pop']['name']\n",
    "        gdp_name = input_pathways['gdp']['name']\n",
    "        \n",
    "        #####\n",
    "        # Iterate through the groups and calculate the pathways per group.\n",
    "        for group_act in groups:\n",
    "            #####\n",
    "            # Set up 'pathways_act' for the current group.\n",
    "            pathways_act = pd.DataFrame(index=[emi_bl_name, pc_cov_name, pop_name, gdp_name, 'unconditional_worst', 'unconditional_best', 'conditional_worst', 'conditional_best'],\n",
    "                                        columns=pathways_groups.columns)\n",
    "            #####\n",
    "            # ISO3s of the current group.\n",
    "            isos_act = sorted(get_isos_groups(group_act, 'ISO3'))\n",
    "            pathways_act.loc[:, 'iso3s'] = ', '.join(isos_act) # Original isos for the group.\n",
    "            # Remove EU28 single countries, if EU28 is in the list.\n",
    "            if 'EU28' in isos_act:\n",
    "                isos_act = sorted(set(isos_act) - set(isos['EU28']))\n",
    "            # endif\n",
    "            # If all EU28 single countries are in the list, but EU28 is not, put it in and remove the single countries.\n",
    "            if ('EU28' not in isos_act and len([1 for xx in isos['EU28'] if xx in isos_act])) == len(isos['EU28']):\n",
    "                isos_act = sorted(set(isos_act + ['EU28']) - set(isos['EU28']))\n",
    "            # endif\n",
    "            pathways_act.loc[:, 'iso3s_adapted'] = ', '.join(isos_act) # Adapted isos for the group, regarding the handling of EU28 and its single countries.\n",
    "            \n",
    "            #####\n",
    "            # Baseline emissions and pc_cov.\n",
    "            emi_bl_act = pathways_all.loc[(pathways_all.iso3.isin(isos_act)) &\n",
    "                (pathways_all.entity == input_pathways['emi_bl']['ent']) & (pathways_all.category == input_pathways['emi_bl']['cat']) & (pathways_all.unit == units['emi']) &\n",
    "                ~(pathways_all.rge.isin(['best', 'worst'])), :]\n",
    "            emi_bl_act.index = emi_bl_act.iso3\n",
    "            # Calculate pc_cov from the per-country covered emissions, divided by the total emissions of these countries.\n",
    "            pc_cov_act = pathways_all.loc[(pathways_all.iso3.isin(isos_act)) & (pathways_all.entity == input_pathways['pc_cov']['ent']), :]\n",
    "            pc_cov_act.index = pc_cov_act.iso3\n",
    "            emi_cov_act = emi_bl_act.loc[:, yrs_all_str].multiply(pc_cov_act.loc[:, yrs_all_str]/100.).loc[:, yrs_all_str].sum(axis=0)\n",
    "            pc_cov_act = emi_cov_act.div(emi_bl_act.loc[:, yrs_all_str].sum(axis=0)) * 100.\n",
    "            #####\n",
    "            # Baseline emissions\n",
    "            pathways_act.loc[emi_bl_name, yrs_all_str] = emi_bl_act.loc[:, yrs_all_str].sum(axis=0).values\n",
    "            pathways_act.loc[emi_bl_name, 'iso3s_missing'] = ', '.join(sorted(set(set(isos_act) - set(emi_bl_act.index))))\n",
    "            pathways_act.loc[emi_bl_name, ['entity', 'category', 'unit', 'gwp']] = [input_pathways['emi_bl']['ent'], input_pathways['emi_bl']['cat'], units['emi'], gwp]\n",
    "            #####\n",
    "            # pc_cov\n",
    "            pathways_act.loc[pc_cov_name, yrs_all_str] = pc_cov_act[yrs_all_str].values\n",
    "            pathways_act.loc[pc_cov_name, 'iso3s_missing'] = ', '.join(sorted(set(set(isos_act) - set(pc_cov_act.index))))\n",
    "            pathways_act.loc[pc_cov_name, ['entity', 'category', 'unit', 'gwp']] = [input_pathways['pc_cov']['ent'], input_pathways['pc_cov']['cat'], '%', gwp]\n",
    "            #####\n",
    "            # Population\n",
    "            ptw_act = pathways_all.loc[(pathways_all.iso3.isin(isos_act)) &\n",
    "                (pathways_all.entity == 'pop'), :]\n",
    "            pathways_act.loc[pop_name, yrs_all_str] = ptw_act.loc[:, yrs_all_str].sum(axis=0).values\n",
    "            pathways_act.loc[pop_name, 'iso3s_missing'] = ', '.join(sorted(set(set(isos_act) - set(ptw_act.index))))\n",
    "            pathways_act.loc[pop_name, ['entity', 'category', 'unit']] = [input_pathways['pop']['ent'], input_pathways['pop']['cat'], units['pop']]\n",
    "            #####\n",
    "            # GDP\n",
    "            ptw_act = pathways_all.loc[(pathways_all.iso3.isin(isos_act)) &\n",
    "                (pathways_all.entity == 'gdp'), :]\n",
    "            pathways_act.loc[gdp_name, yrs_all_str] = ptw_act.loc[:, yrs_all_str].sum(axis=0).values\n",
    "            pathways_act.loc[gdp_name, 'iso3s_missing'] = ', '.join(sorted(set(set(isos_act) - set(ptw_act.index))))\n",
    "            pathways_act.loc[gdp_name, ['entity', 'category', 'unit']] = [input_pathways['gdp']['ent'], input_pathways['gdp']['cat'], units['gdp']]\n",
    "            #####\n",
    "            # Unconditional_worst\n",
    "            ptw_act = pathways_all.loc[(pathways_all.iso3.isin(isos_act)) &\n",
    "                (pathways_all.entity == input_pathways['emi_bl']['ent']) & (pathways_all.category == input_pathways['emi_bl']['cat']) & (pathways_all.unit == units['emi']) &\n",
    "                (pathways_all.condi == 'unconditional') & (pathways_all.rge == 'worst'), :]\n",
    "            pathways_act.loc['unconditional_worst', yrs_all_str] = ptw_act.loc[:, yrs_all_str].sum(axis=0).values\n",
    "            pathways_act.loc['unconditional_worst', 'iso3s_missing'] = ', '.join(sorted(set(set(isos_act) - set(ptw_act.index))))\n",
    "            pathways_act.loc['unconditional_worst', ['condi', 'rge', 'entity', 'category', 'unit', 'gwp']] = \\\n",
    "                ['unconditional', 'worst', input_pathways['emi_bl']['ent'], input_pathways['emi_bl']['cat'], units['emi'], gwp]\n",
    "            #####\n",
    "            # Unconditional_best\n",
    "            ptw_act = pathways_all.loc[(pathways_all.iso3.isin(isos_act)) &\n",
    "                (pathways_all.entity == input_pathways['emi_bl']['ent']) & (pathways_all.category == input_pathways['emi_bl']['cat']) & (pathways_all.unit == units['emi']) &\n",
    "                (pathways_all.condi == 'unconditional') & (pathways_all.rge == 'best'), :]\n",
    "            pathways_act.loc['unconditional_best', yrs_all_str] = ptw_act.loc[:, yrs_all_str].sum(axis=0).values\n",
    "            pathways_act.loc['unconditional_best', 'iso3s_missing'] = ', '.join(sorted(set(set(isos_act) - set(ptw_act.index))))\n",
    "            pathways_act.loc['unconditional_best', ['condi', 'rge', 'entity', 'category', 'unit', 'gwp']] = \\\n",
    "                ['unconditional', 'best', input_pathways['emi_bl']['ent'], input_pathways['emi_bl']['cat'], units['emi'], gwp]\n",
    "            #####\n",
    "            # Conditional_worst\n",
    "            ptw_act = pathways_all.loc[(pathways_all.iso3.isin(isos_act)) &\n",
    "                (pathways_all.entity == input_pathways['emi_bl']['ent']) & (pathways_all.category == input_pathways['emi_bl']['cat']) & (pathways_all.unit == units['emi']) &\n",
    "                (pathways_all.condi == 'conditional') & (pathways_all.rge == 'worst'), :]\n",
    "            pathways_act.loc['conditional_worst', yrs_all_str] = ptw_act.loc[:, yrs_all_str].sum(axis=0).values\n",
    "            pathways_act.loc['conditional_worst', 'iso3s_missing'] = ', '.join(sorted(set(set(isos_act) - set(ptw_act.index))))\n",
    "            pathways_act.loc['conditional_worst', ['condi', 'rge', 'entity', 'category', 'unit', 'gwp']] = \\\n",
    "                ['conditional', 'worst', input_pathways['emi_bl']['ent'], input_pathways['emi_bl']['cat'], units['emi'], gwp]\n",
    "            #####\n",
    "            # Conditional_best\n",
    "            ptw_act = pathways_all.loc[(pathways_all.iso3.isin(isos_act)) &\n",
    "                (pathways_all.entity == input_pathways['emi_bl']['ent']) & (pathways_all.category ==input_pathways['emi_bl']['cat']) & (pathways_all.unit == units['emi']) &\n",
    "                (pathways_all.condi == 'conditional') & (pathways_all.rge == 'best'), yrs_all_str]\n",
    "            pathways_act.loc['conditional_best', yrs_all_str] = ptw_act.sum(axis=0).values\n",
    "            pathways_act.loc['conditional_best', 'iso3s_missing'] = ', '.join(sorted(set(set(isos_act) - set(ptw_act.index))))\n",
    "            pathways_act.loc['conditional_best', ['condi', 'rge', 'entity', 'category', 'unit', 'gwp']] = \\\n",
    "                ['conditional', 'best', input_pathways['emi_bl']['ent'], input_pathways['emi_bl']['cat'], units['emi'], gwp]\n",
    "            #####\n",
    "            # General input\n",
    "            pathways_act.loc[:, 'group'] = group_act\n",
    "            \n",
    "            #####\n",
    "            pathways_groups = pathways_groups.append(pathways_act, ignore_index=True)\n",
    "        # endfor\n",
    "        \n",
    "        #####\n",
    "        # Write out 'pathways_groups'.\n",
    "        pathways_groups.to_csv(Path(path_output, file_name), index=False)\n",
    "        print(\"done calculating the per-group pathways ...\")\n",
    "        \n",
    "        #####\n",
    "        return pathways_groups\n",
    "    # enddef\n",
    "    \n",
    "    # %%\n",
    "    # Get iso3s for EU28, EARTH (only the iso3s with independent data).\n",
    "    # data_included_in_other_isos: information from G端tschow et al., 2016.\n",
    "    isos = {'EU28': get_isos_groups('EU28', 'ISO3'),\n",
    "            'data_included_in_other_isos': get_isos_groups('ISO3_dependent_without_independent_data', 'ISO3')}\n",
    "    # From emissions module: get_members_of('EARTH'):\n",
    "    isos_earth = get_isos_groups('EARTH', 'ISO3')\n",
    "    # As EARTH: only use the iso3s that have independent data:\n",
    "    data_not_included_in_other_isos = sorted(set((set(isos_earth) - set(isos['data_included_in_other_isos']))))\n",
    "    isos['EARTH'] = data_not_included_in_other_isos\n",
    "    \n",
    "    # %%\n",
    "    ##########################\n",
    "    ##### ndc_type_prios #####\n",
    "    ##########################\n",
    "    \n",
    "    # If countries are 'ALL', replace them by all ISO3s.\n",
    "    if ndc_type_prios['countries'] == ['ALL']:\n",
    "        ndc_type_prios['countries'] = sorted(isos['EARTH'] + ['EU28'])\n",
    "    # endif\n",
    "    # Only chose valid values. If no valid values are given it is set to TYPE_CALC and ALL countries.\n",
    "    ndc_type_prios_val = [xx for xx in ndc_type_prios['ndc_type_prios']\n",
    "                          if xx in ['TYPE_CALC', 'TYPE_ORIG', 'ABS', 'BYT', 'RRB', 'ARB', 'RIT', 'AIT', 'NGT']]\n",
    "    if len(ndc_type_prios_val) < len(ndc_type_prios['ndc_type_prios']):\n",
    "        if len(ndc_type_prios_val) == 0:\n",
    "            ndc_type_prios['ndc_type_prios'] = ['TYPE_CALC']\n",
    "        else:\n",
    "            ndc_type_prios['ndc_type_prios'] = ndc_type_prios_val\n",
    "        # endif\n",
    "        print(\"Warning in main_ndc_quantifications.ipynb: error in input for 'ndc_type_prios' (ndc_type_prios)!\")\n",
    "    # endif\n",
    "    ndc_type_prios_ctr = [xx for xx in ndc_type_prios['countries']\n",
    "                         if xx in isos['EARTH'] + ['EU28']]\n",
    "    if len(ndc_type_prios_ctr) < len(ndc_type_prios['countries']):\n",
    "        if len(ndc_type_prios_ctr) == 0:\n",
    "            ndc_type_prios['countries'] = sorted(isos['EARTH'] + ['EU28'])\n",
    "        else:\n",
    "            ndc_type_prios['countries'] = ndc_type_prios_ctr\n",
    "        # endif\n",
    "        print(\"Warning in main_ndc_quantifications.ipynb: error in input for 'ndc_type_prios' (countries)!\")\n",
    "    # endif\n",
    "    \n",
    "    #########################\n",
    "    ##### pc_cov_predef #####\n",
    "    #########################\n",
    "    \n",
    "    # If pc_cov_predef is given and between 0 and 100 (%), use the value for all targets. Else use pc_cov from time_series.\n",
    "    if pc_cov_predef['use_pc_cov_predef']:\n",
    "        pc_cov_predef['pc_cov_predef'] = 100.\n",
    "        if pc_cov_predef['countries'] == ['ALL']:\n",
    "            pc_cov_predef['countries'] = sorted(isos['EARTH'] + ['EU28'])\n",
    "        # endif\n",
    "        pc_cov_predef_ctr = [xx for xx in pc_cov_predef['countries'] if xx in isos['EARTH'] + ['EU28']]\n",
    "        if len(pc_cov_predef_ctr) < len(pc_cov_predef['countries']):\n",
    "            if len(pc_cov_predef_ctr) == 0:\n",
    "                pc_cov_predef['countries'] = sorted(isos['EARTH'] + ['EU28'])\n",
    "            else:\n",
    "                pc_cov_predef['countries'] = pc_cov_predef_ctr\n",
    "            # endif\n",
    "            print(\"Warning in main_ndc_quantifications.ipynb: error in input for 'pc_cov_predef' (countries)!\")\n",
    "        # endif\n",
    "    # endif\n",
    "    \n",
    "    ##########################\n",
    "    ##### ndc_strengthen #####\n",
    "    ##########################\n",
    "    \n",
    "    # If ndc_strengthen['pc'] is not inbetween 0 and 100 (%), give out warning and do not use it.\n",
    "    if ndc_strengthen['use_ndc_strengthen']:\n",
    "        if (ndc_strengthen['pc'] < 0) or (ndc_strengthen['pc'] > 100):\n",
    "            print(\"Warning in main_ndc_quantifications.ipynb: error in input for ndc_strengthen['pc']. \" +\n",
    "                  \"Value exceeds limits. It is not used.\")\n",
    "            ndc_strengthen['use_ndc_strengthen'] = False\n",
    "        elif ndc_strengthen['how_to'] not in ['add', 'multiply']:\n",
    "            print(\"Warning in main_ndc_quantifications.ipynb: error in input for ndc_strengthen['how_to']. \" +\n",
    "                  \"Value should be 'add' or 'multiply'. It is not used.\")\n",
    "            ndc_strengthen['use_ndc_strengthen'] = False\n",
    "        else:\n",
    "            ndc_strengthen['use_ndc_strengthen'] = True\n",
    "            if ndc_strengthen['countries'] == ['ALL']:\n",
    "                ndc_strengthen['countries'] = sorted(isos['EARTH'] + ['EU28'])\n",
    "            # endif\n",
    "            ndc_strengthen_ctr = [xx for xx in ndc_strengthen['countries'] if xx in isos['EARTH'] + ['EU28']]\n",
    "            if len(ndc_strengthen_ctr) < len(ndc_strengthen['countries']):\n",
    "                if len(ndc_strengthen_ctr) == 0:\n",
    "                    ndc_strengthen['countries'] = sorted(isos['EARTH'] + ['EU28'])\n",
    "                else:\n",
    "                    ndc_strengthen['countries'] = ndc_strengthen_ctr\n",
    "                # endif\n",
    "                print(\"Warning in main_ndc_quantifications.ipynb: error in input for 'ndc_strengthen' (countries)!\")\n",
    "            # endif\n",
    "        # endif\n",
    "    # endif\n",
    "    \n",
    "    # %%\n",
    "    #####\n",
    "    # Units (all emissions have to be given in MtCO2eq, pop in Pers, and gdp in 2011GKD)\n",
    "    units = {'emi': 'MtCO2eq', 'pop': 'Pers', 'gdp': '2011GKD'}\n",
    "    \n",
    "    #####\n",
    "    # Years (all: 1990 to 2050, pathways: 2017 to 2050)\n",
    "    yrs_all_int = range(1990, 2051)\n",
    "    yrs_pathway_int = range(2017, 2051)\n",
    "    yrs_all_str = ['Y' + str(xx) for xx in yrs_all_int]\n",
    "    yrs_pathway_str = ['Y' + str(xx) for xx in yrs_pathway_int]\n",
    "    \n",
    "    ########################\n",
    "    ##### Get NDC info #####\n",
    "    ########################\n",
    "    \n",
    "    # Get information from NDCs (only the rows with \".mod\" in the name).\n",
    "    ndc = pd.read_excel(ndc_path, sheet_name=ndc_sheet, index_col=0, header=None).astype('str')\n",
    "    ndc.drop(index=[xx for xx in list(ndc.index) if (not type(xx) == str) or (xx[-4:] != '.mod')], inplace=True)\n",
    "    ndc.index = [xx[:-4] for xx in ndc.index]\n",
    "    ndc.columns = ndc.loc['ISO3', :]\n",
    "    \n",
    "    ############################\n",
    "    ##### Read time series #####\n",
    "    ############################\n",
    "    \n",
    "    # Read in time series 1990-2050 (and add EU28 sum if not included yet; fill missing values at the end with mean over 2010 to most recent available value).\n",
    "    time_series = {}\n",
    "    time_series = func_int_read_in_time_series(time_series, time_series_path, yrs_all_str, isos)\n",
    "    # LULUCF:\n",
    "    if calc_lu:\n",
    "        time_series = func_int_read_in_time_series_lu(time_series, time_series_lu_path, isos)\n",
    "    # endif\n",
    "    \n",
    "    # %%\n",
    "    ########################\n",
    "    ##### CALCULATIONS #####\n",
    "    ########################\n",
    "    \n",
    "    #####\n",
    "    # Calculate the target emissions per country and un/conditional & best/worst & year.\n",
    "    data_out = func_int_calc_targets(time_series, units, ndc, isos, gwp, scenario, yrs_all_str, path_output, calc_lu, \n",
    "                                     pc_cov_predef, ndc_strengthen)\n",
    "    \n",
    "    #####\n",
    "    # Calculate the emissions pathways for un/conditional_best/worst targets, per country.\n",
    "    # For countries with baseline emissions, but without target, use the baseline emissions.\n",
    "    # Excl. LULUCF.\n",
    "    input_pathways = {'emi_bl': {'name': 'IPCM0EL', 'ent': 'KYOTOGHG', 'cat': 'IPCM0EL'},\n",
    "                      'pc_cov': {'name': 'pc_cov_excl_lu', 'ent': 'pc_cov_excl_lu', 'cat': 'IPCM0EL'},\n",
    "                      'pop': {'name': 'pop', 'ent': 'pop', 'cat': 'DEMOGR'},\n",
    "                      'gdp': {'name': 'gdp', 'ent': 'gdp', 'cat': 'ECO'}}\n",
    "    target_name = 'tar_emi_excl_lu' # Or target_name = 'tar_emi_tot', 'tar_emi_only_lu'\n",
    "    file_name = 'ndc_targets_excl_lulucf_pathways.csv'\n",
    "    pathways_all_excl_lu = func_int_calc_pathways_per_country(time_series, data_out, input_pathways, target_name, file_name, \n",
    "                                                              path_output, yrs_all_str, yrs_pathway_str, isos, units, ndc_type_prios)\n",
    "    if calc_lu:\n",
    "        # Only LULUCF.\n",
    "        input_pathways = {'emi_bl': {'name': 'IPCMLULUCF', 'ent': 'KYOTOGHG', 'cat': 'IPCMLULUCF'},\n",
    "                          'pc_cov': {'name': 'pc_cov_lu', 'ent': 'pc_cov_lu', 'cat': 'IPCMLULUCF'},\n",
    "                          'pop': {'name': 'pop', 'ent': 'pop', 'cat': 'DEMOGR'},\n",
    "                          'gdp': {'name': 'gdp', 'ent': 'gdp', 'cat': 'ECO'}}\n",
    "        target_name = 'tar_emi_lu_only' # Or target_name = 'tar_emi_tot', 'tar_emi_lu_only'\n",
    "        file_name = 'ndc_targets_only_lulucf_pathways.csv'\n",
    "        pathways_all_lu = func_int_calc_pathways_per_country(time_series, data_out, input_pathways, target_name, file_name, \n",
    "                                                             path_output, yrs_all_str, yrs_pathway_str, isos, units, ndc_type_prios)\n",
    "    # endif\n",
    "    \n",
    "    #####\n",
    "    # Calculate the emissions pathways for un/conditional_best/worst targets, per group of countries.\n",
    "    # Excl. LULUCF.\n",
    "    input_pathways = {'emi_bl': {'name': 'IPCM0EL', 'ent': 'KYOTOGHG', 'cat': 'IPCM0EL'},\n",
    "                     'pc_cov': {'name': 'pc_cov_excl_lu', 'ent': 'pc_cov_excl_lu', 'cat': 'IPCM0EL'},\n",
    "                     'pop': {'name': 'pop', 'ent': 'pop', 'cat': 'DEMOGR'},\n",
    "                     'gdp': {'name': 'gdp', 'ent': 'gdp', 'cat': 'ECO'}}\n",
    "    file_name = 'ndc_targets_excl_lulucf_pathways_groups.csv'\n",
    "    func_int_calc_pathway_per_group(pathways_all_excl_lu, input_pathways, yrs_all_str, isos, units, gwp, path_output, file_name)\n",
    "    if calc_lu:\n",
    "        # Only LULUCF.\n",
    "        input_pathways = {'emi_bl': {'name': 'IPCMLULUCF', 'ent': 'KYOTOGHG', 'cat': 'IPCMLULUCF'},\n",
    "                         'pc_cov': {'name': 'pc_cov_lu', 'ent': 'pc_cov_lu', 'cat': 'IPCMLULUCF'},\n",
    "                         'pop': {'name': 'pop', 'ent': 'pop', 'cat': 'DEMOGR'},\n",
    "                         'gdp': {'name': 'gdp', 'ent': 'gdp', 'cat': 'ECO'}}\n",
    "        file_name = 'ndc_targets_only_lulucf_pathways_groups.csv'\n",
    "        func_int_calc_pathway_per_group(pathways_all_lu, input_pathways, yrs_all_str, isos, units, gwp, path_output, file_name)\n",
    "    # endif\n",
    "    \n",
    "    # %%\n",
    "    print('... everything is over!!!')\n",
    "\n",
    "    # %%\n",
    "# enddef"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
